{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dye recognition\n",
    "\n",
    "Here is the Jupyter Notebook used for the dye recognition and the visualization tools developped.\n",
    "\n",
    "After generating a database using creation_spectra_base.py, you can import an hyperspectral image here and use the pearson coefficient method to get the visualization we developped.\n",
    "\n",
    "\n",
    "## Import\n",
    "\n",
    "Run it two time to get the interactive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import mpl_scatter_density\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as colors\n",
    "import spectral.io.envi as envi\n",
    "from spectral import imshow\n",
    "import cv2\n",
    "from scipy.stats.stats import pearsonr   \n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# Affichage du PCA sur un graphe 2D\n",
    "# \"Viridis-like\" colormap with white background\n",
    "white_viridis = LinearSegmentedColormap.from_list('white_viridis', [\n",
    "    (0, '#ffffff'),\n",
    "    (1e-20, '#440053'),\n",
    "    (0.2, '#404388'),\n",
    "    (0.4, '#2a788e'),\n",
    "    (0.6, '#21a784'),\n",
    "    (0.8, '#78d151'),\n",
    "    (1, '#fde624'),\n",
    "], N=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input for the dyes studies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "filename = \"D://Spectral//Aubusson/Fleur//\"\n",
    "\n",
    "# Name of the file, usually \"001\"\n",
    "img_nbr = \"001\"\n",
    "\n",
    "# Name of the database for reference spectra used\n",
    "database_name = \"red_dyes\"\n",
    "#-----------------------------------------------\n",
    "# Region of interest definition\n",
    "point_1 = [616, 912]\n",
    "point_2 = [1274,1391]\n",
    "#-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the database of reference spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = csv.reader(open('data//databases//'+database_name+'.csv', mode='r'))\n",
    "\n",
    "pigments_dic = {}\n",
    "for row in reader:\n",
    "    pigments_dic[row[0]]=[float(i) for i in row[1:]]\n",
    "\n",
    "pigments = np.array([pigments_dic[key] for key in pigments_dic.keys()])\n",
    "label = np.array([key for key in pigments_dic.keys()])\n",
    "\n",
    "bands = np.array(np.genfromtxt('bands_long.csv', delimiter=','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i = 0\n",
    "for pig in pigments :\n",
    "    plt.plot(bands, pig, label = label[i])\n",
    "    i = i +1\n",
    "    \n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Reference spectra')\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Reflectance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the hyperspectral image studied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(filename+'array_white.txt') == False :\n",
    "    # Creation of white and dark reference\n",
    "    white_nparr = np.array(envi.open(filename+\"WHITEREF_\"+img_nbr+\".hdr\", filename+\"WHITEREF_\"+img_nbr+\".raw\").load())\n",
    "\n",
    "    white_val = []\n",
    "    for i in range(840):\n",
    "        white_val.append(np.mean(white_nparr[:,:, i]))\n",
    "    file1 = open(filename+'array_white.txt',\"w\")\n",
    "    np.savetxt(file1, [white_val])\n",
    "    file1.close()\n",
    "\n",
    "    dark_nparr = np.array(envi.open(filename+\"DARKREF_\"+img_nbr+\".hdr\", filename+\"DARKREF_\"+img_nbr+\".raw\").load())\n",
    "    print(np.min(dark_nparr))\n",
    "    dark_val = []\n",
    "    for i in range(840):\n",
    "        dark_val.append(np.mean(dark_nparr[:,:, i]))\n",
    "    dark_val[0] = dark_val[1]\n",
    "    file1 = open(filename+'array_dark.txt',\"w\")\n",
    "    np.savetxt(file1, [dark_val])\n",
    "    file1.close()\n",
    "\n",
    "    del white_nparr, white_val, dark_nparr, dark_val\n",
    "\n",
    "# Import the image    \n",
    "data_nparr = (envi.open(filename+img_nbr+\".hdr\", filename+img_nbr+\".raw\").load())[100:-100, 100:-100,:]\n",
    "        \n",
    "# Import reference\n",
    "white_file = open(filename+'array_white.txt',\"r\")\n",
    "white_val = np.loadtxt(white_file)\n",
    "\n",
    "dark_file = open(filename+'array_dark.txt',\"r\")\n",
    "dark_val = np.loadtxt(dark_file)\n",
    "dark_val[0] = dark_val[1]\n",
    "\n",
    "cut_corrected_nparr = data_nparr[point_1[0]:point_2[0] , point_1[1]:point_2[1],:]\n",
    "\n",
    "cut_corrected_nparr = np.divide(\n",
    "        np.subtract(cut_corrected_nparr, dark_val),\n",
    "        np.subtract(white_val, dark_val))\n",
    "\n",
    "# Plot the image\n",
    "imshow(cut_corrected_nparr, (73*4, 52*4, 23*4))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilateral filtering\n",
    "c_map = cut_corrected_nparr.astype(np.float32, copy=False)\n",
    "for i in range(len(cut_corrected_nparr[0][0])):\n",
    "    img = np.array(cv2.bilateralFilter(c_map[:,:,i], 20, 0.1, 45))\n",
    "    cut_corrected_nparr[:,:,i] = img\n",
    "plt.tight_layout()\n",
    "\n",
    "imshow(cut_corrected_nparr, (73*4, 52*4, 23*4))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on the pearson coefficients and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the correlation maps\n",
    "correlation_maps = np.zeros((np.shape(cut_corrected_nparr)[0],\n",
    "                             np.shape(cut_corrected_nparr)[1],\n",
    "                             np.shape(pigments)[0]))\n",
    "\n",
    "for x in range(np.shape(correlation_maps)[0]):\n",
    "            for y in range(np.shape(correlation_maps)[1]):\n",
    "                for z in range(np.shape(correlation_maps)[2]):\n",
    "                    b = cut_corrected_nparr[x, y,:]/sum(cut_corrected_nparr[x, y,:])\n",
    "                    a = np.array(pigments[z, :])\n",
    "                    corr_x, corr_y = pearsonr(a,b)\n",
    "                    correlation_maps[x, y, z] = corr_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the PCA on our data\n",
    "data = np.reshape(correlation_maps,\n",
    "                   (np.shape(correlation_maps)[0]*np.shape(correlation_maps)[1],np.shape(correlation_maps)[2])).T\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)\n",
    "\n",
    "img_pca = pca.components_[:,:np.shape(correlation_maps)[0]*np.shape(correlation_maps)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 70\n",
    "\n",
    "# Interactive plot: \n",
    "class Cursor:\n",
    "    def __init__(self, fig, ax, ax2, ax3, img, data, spect_img, rad):\n",
    "        self.fig = fig\n",
    "        self.ax = ax\n",
    "        self.ax2 = ax2\n",
    "        self.ax3 = ax3\n",
    "        self.ly = ax.axvline(color='k')  # the vert line\n",
    "        self.lx = ax.axhline(color='k')  # the vert line\n",
    "        self.data = data\n",
    "        self.img = img\n",
    "        self.spect_img = spect_img\n",
    "        self.value = 5\n",
    "        self.rad = rad\n",
    "\n",
    "        # text location in axes coords\n",
    "        self.txt = ax.text(0.05, 0.95, '', transform=ax.transAxes)\n",
    "\n",
    "    def mouse_move(self, event):\n",
    "        if not event.inaxes:\n",
    "            return\n",
    "\n",
    "        x = event.xdata\n",
    "        y = event.ydata\n",
    "        # update the line positions\n",
    "        self.ly.set_xdata(x)\n",
    "        self.lx.set_ydata(y)\n",
    "\n",
    "        # Image avec rouge\n",
    "        self.txt.set_text('value= x:'+str(round(x,5))+' y:'+str(round(y,5)))\n",
    "        img2 = np.zeros((np.shape(self.img)[0], np.shape(self.img)[1], 3))\n",
    "        img2[np.sqrt((self.data[:,:,0]-x)**2+(self.data[:,:,1]-y)**2) < self.rad] = [1, 0, 0]\n",
    "        img2[np.sqrt((self.data[:,:,0]-x)**2+(self.data[:,:,1]-y)**2) >= self.rad] = self.img[np.sqrt((self.data[:,:,0]-x)**2+(self.data[:,:,1]-y)**2) >= self.rad]\n",
    "        \n",
    "        self.ax2 = fig.add_subplot(2,2,3)\n",
    "        self.ax2 = plt.imshow(img2)\n",
    "        self.ax2 = plt.axis('off')\n",
    "        \n",
    "        # Spectre normalisÃ© \n",
    "        pca_data = np.reshape(self.data, (np.shape(self.data)[0]*np.shape(self.data)[1], 2))\n",
    "        mask = np.ma.masked_where(np.sqrt((pca_data[:,0]-x)**2+(pca_data[:,1]-y)**2) > self.rad, pca_data[:,0])\n",
    "        mask = np.reshape(0*mask+1, (np.shape(self.img)[0], np.shape(self.img)[1]))\n",
    "        spectrum = []\n",
    "        for i in range(np.shape(self.spect_img)[2]):\n",
    "            spectrum.append(np.mean(mask*self.spect_img[:,:,i]))\n",
    "        self.ax3 = fig.add_subplot(2,2,4)\n",
    "        self.ax3 = plt.cla()\n",
    "        self.ax3 = plt.plot(bands, spectrum)\n",
    "        self.ax3 = plt.grid()\n",
    "        self.ax3 = plt.title('Selected spectrum')\n",
    "        \n",
    "        self.ax.figure.canvas.draw()\n",
    "        \n",
    "rgb_img = np.zeros((np.shape(cut_corrected_nparr)[0], np.shape(cut_corrected_nparr)[1], 3))\n",
    "rgb_img[:,:,0] = cut_corrected_nparr[:,:,74*4]\n",
    "rgb_img[:,:,1] = cut_corrected_nparr[:,:,52*4]\n",
    "rgb_img[:,:,2] = cut_corrected_nparr[:,:,23*4]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(2, 1, 1, projection='scatter_density')\n",
    "ax.grid()\n",
    "density = ax.scatter_density(img_pca[:][0], img_pca[:][1], cmap=white_viridis, vmin= 0, vmax=vmax, alpha = 1)\n",
    "\n",
    "ax2 = fig.add_subplot(2,2,4)\n",
    "\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "\n",
    "\n",
    "pca2img = np.zeros((np.shape(rgb_img)[0],np.shape(rgb_img)[1], 2))\n",
    "pca2img[:,:,0] = np.reshape(img_pca[:][0],\n",
    "                   (np.shape(rgb_img)[0],np.shape(rgb_img)[1]))\n",
    "pca2img[:,:,1] = np.reshape(img_pca[:][1],\n",
    "                   (np.shape(rgb_img)[0],np.shape(rgb_img)[1]))\n",
    "\n",
    "\n",
    "\n",
    "cursor = Cursor(fig, ax, ax2, ax3, rgb_img, pca2img, cut_corrected_nparr, 0.0002)\n",
    "fig.canvas.mpl_connect('button_press_event', cursor.mouse_move)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
